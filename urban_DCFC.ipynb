{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## DCFC EVCS POI Candidate Selection - Atlanta\n",
    "\n",
    "**Atlanta**: Since a larger number of DCFC-type EVCS (Electric Vehicle Charging Stations) are installed in Atlanta compared to other regions, an initial **POI filtering** was conducted to identify potential locations for DCFC installation. Additionally, to further refine the placement of DCFC EVCS, **case-specific optimization** was applied. This process first involved running an optimization for **Level 2 EVCS** installations. The results from this optimization were then used as additional candidates for DCFC installation.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "  \n",
    "- **DCFC POI Candidate Selection**: Atlanta, using GIS tools, filtering, and optimization of Level 2 EVCS results.  \n",
    "\n",
    "-  **POI Filtering Results** + **Optimization of Level 2 EVCS** = Final **DCFC EVCS Candidates** for Atlanta.  \n",
    "<br>\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCFC POI Candidate Selection - Atlanta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from shapely.geometry import box, Point\n",
    "from rasterio.mask import geometry_mask\n",
    "\n",
    "from src import setup_logging, greedy_optimization, process_ev_charging_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the YAML file with fclass categories\n",
    "yaml_file_path = 'poi_filtering.yaml'\n",
    "\n",
    "with open(yaml_file_path, 'r') as file:\n",
    "    fclass_data = yaml.safe_load(file)\n",
    "\n",
    "# 2. Extract the list of categories for 'atlanta_dcfc' from the YAML data\n",
    "if 'atlanta_dcfc' in fclass_data['candidate']:\n",
    "    selected_category = fclass_data['candidate']['atlanta_dcfc']\n",
    "else:\n",
    "    raise ValueError(\"The 'atlanta_dcfc' category is not found in the YAML file.\")\n",
    "\n",
    "# 3. File paths (Modify these paths as per your file locations)\n",
    "gpkg_file_path = \"Path to your Atlanta Region POI\"\n",
    "result_of_atlanta = 'Path to Optimization Result in Atlanta' \n",
    "\n",
    "# 4. Read the GPKG files\n",
    "poi_gdf = gpd.read_file(gpkg_file_path)\n",
    "poi2_gdf = gpd.read_file(result_of_atlanta)\n",
    "\n",
    "# 5. Filter rows from the 'fclass' column that match the selected categories\n",
    "poi_gdf = poi_gdf[poi_gdf['fclass'].isin(selected_category)]\n",
    "\n",
    "# 6. Prepare the second GeoDataFrame\n",
    "poi2_gdf = poi2_gdf[['osm_id', 'fclass', 'geometry']]\n",
    "\n",
    "# 7. Merge the two GeoDataFrames and remove duplicates based on 'osm_id'\n",
    "merged = pd.concat([poi_gdf, poi2_gdf], ignore_index=True)\n",
    "merged = merged.drop_duplicates(subset='osm_id')\n",
    "\n",
    "# 8. Convert the merged DataFrame back to a GeoDataFrame\n",
    "merged_gdf = gpd.GeoDataFrame(merged, geometry='geometry')\n",
    "\n",
    "# 9. Save the merged GeoDataFrame to a new GeoPackage file\n",
    "output_file_path = \"atlanta_dcfc_poi_candidate.gpkg\"\n",
    "merged_gdf.to_file(output_file_path, driver=\"GPKG\")\n",
    "\n",
    "print(f\"Filtered and merged POI data saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Case 2: Atlanta DCFC EVCS Charger Initial Point Selection\n",
    "\n",
    "The **Atlanta** area is a key region for the installation of numerous **DCFC** (Direct Current Fast Chargers).  \n",
    "Since the optimal location of DCFCs can be critical to traffic flow, we use the **road network** to guide the selection of initial points.\n",
    "\n",
    "### Algorithm:\n",
    "\n",
    "1. **Map demand values** using the **Motorway** and **Trunkway Demand Map**. Start by selecting POIs adjacent to the roads with the highest demand values based on the following criteria:\n",
    "2. Find **POI candidates** near roads with high demand values, and ensure that the selected POIs maintain a **minimum distance of 3 km**, which is the minimum service radius for EVCS.\n",
    "3. Select the specified number of **initial POIs**, repeating the process until the required number of points is reached.\n",
    "4. If fewer than 5 POIs are selected in a specific area, the process reads the **Demand Map's pixel values** directly to identify high-demand regions and select additional POI candidates.  \n",
    "<br>  \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "def load_data():\n",
    "    motorway_gdf = gpd.read_file('Path_to_Motorway_Road_Network.gpkg')  # Load motorway road network\n",
    "    trunk_gdf = gpd.read_file('Path_to_Trunk_Road_Network.gpkg')  # Load trunk road network\n",
    "    poi_gdf = gpd.read_file('Path_to_DCFC_Candidate_POIs.gpkg')  # Load candidate POIs for DCFC\n",
    "    demand_map = rasterio.open('Path_to_Demand_Map.tif')  # Load demand map raster\n",
    "    boundary_gdf = gpd.read_file('Path_to_Boundary_Polygon.gpkg')  # Load boundary polygon data\n",
    "    return motorway_gdf, trunk_gdf, poi_gdf, demand_map, boundary_gdf\n",
    "\n",
    "# Extract pixel values from demand map based on geometry\n",
    "def extract_demand_values(geometries, demand_map):\n",
    "    demand_values = []\n",
    "    for geom in geometries:\n",
    "        mask = geometry_mask([geom], transform=demand_map.transform, invert=True, out_shape=(demand_map.height, demand_map.width))\n",
    "        pixel_data = demand_map.read(1, masked=True)[mask]\n",
    "        if pixel_data.size > 0:\n",
    "            demand_values.append((geom, np.max(pixel_data)))\n",
    "        else:\n",
    "            demand_values.append((geom, None))\n",
    "    return demand_values\n",
    "\n",
    "# Calculate Euclidean distance in meters (EPSG:3857 is a meter-based projection)\n",
    "def calculate_euclidean_distance(point1, point2):\n",
    "    return point1.distance(point2)\n",
    "\n",
    "# Check if new POI is far enough from existing selected POIs\n",
    "def check_min_distance(selected_pois, new_poi_geom, min_distance_m=3000):\n",
    "    for existing_poi in selected_pois.itertuples():\n",
    "        if calculate_euclidean_distance(existing_poi.geometry, new_poi_geom) < min_distance_m:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Select initial POIs for each region based on demand and proximity\n",
    "def select_initial_pois_for_region(region_boundary, motorway_gdf, trunk_gdf, poi_gdf, demand_map, target_crs):\n",
    "    # Filter roads within region\n",
    "    motorway_in_region = motorway_gdf[motorway_gdf.intersects(region_boundary.unary_union)]\n",
    "    trunk_in_region = trunk_gdf[trunk_gdf.intersects(region_boundary.unary_union)]\n",
    "\n",
    "    # Combine road networks into one GeoDataFrame\n",
    "    combined_roads_gdf = gpd.GeoDataFrame(pd.concat([motorway_in_region, trunk_in_region], ignore_index=True))\n",
    "\n",
    "    # Get demand values for road geometries\n",
    "    road_demand_values = extract_demand_values(combined_roads_gdf.geometry, demand_map)\n",
    "    road_demand_values = [v for v in road_demand_values if v[1] is not None]\n",
    "    road_demand_values.sort(key=lambda x: x[1], reverse=True)  # Sort by demand (descending)\n",
    "\n",
    "    # Select POIs based on demand and proximity\n",
    "    selected_pois_gdf = gpd.GeoDataFrame(columns=poi_gdf.columns, crs=target_crs)\n",
    "    for road_geom, _ in road_demand_values:\n",
    "        candidates_in_area = poi_gdf[poi_gdf.intersects(road_geom)]\n",
    "        for _, candidate_poi in candidates_in_area.iterrows():\n",
    "            candidate_poi_gdf = gpd.GeoDataFrame([candidate_poi], crs=poi_gdf.crs)\n",
    "            if len(selected_pois_gdf) > 0 and not check_min_distance(selected_pois_gdf, candidate_poi_gdf.geometry.iloc[0]):\n",
    "                continue\n",
    "            selected_pois_gdf = pd.concat([selected_pois_gdf, candidate_poi_gdf], ignore_index=True)\n",
    "            if len(selected_pois_gdf) >= 5:\n",
    "                break\n",
    "        if len(selected_pois_gdf) >= 5:\n",
    "            break\n",
    "\n",
    "    # Handle regions with fewer than 5 POIs using demand map directly\n",
    "    if len(selected_pois_gdf) < 5:\n",
    "        pixel_data = demand_map.read(1)\n",
    "        sorted_pixel_indices = np.unravel_index(np.argsort(pixel_data, axis=None)[::-1], pixel_data.shape)\n",
    "        for y, x in zip(sorted_pixel_indices[0], sorted_pixel_indices[1]):\n",
    "            pixel_geom = box(*demand_map.xy(y, x), *demand_map.xy(y + 1, x + 1))\n",
    "            if region_boundary.unary_union.intersects(pixel_geom):\n",
    "                candidates_in_area = poi_gdf[poi_gdf.intersects(pixel_geom)]\n",
    "                for _, candidate_poi in candidates_in_area.iterrows():\n",
    "                    candidate_poi_gdf = gpd.GeoDataFrame([candidate_poi], crs=poi_gdf.crs)\n",
    "                    if len(selected_pois_gdf) > 0 and not check_min_distance(selected_pois_gdf, candidate_poi_gdf.geometry.iloc[0]):\n",
    "                        continue\n",
    "                    selected_pois_gdf = pd.concat([selected_pois_gdf, candidate_poi_gdf], ignore_index=True)\n",
    "                    if len(selected_pois_gdf) >= 5:\n",
    "                        break\n",
    "            if len(selected_pois_gdf) >= 5:\n",
    "                break\n",
    "\n",
    "    return selected_pois_gdf\n",
    "\n",
    "# Main logic to select POIs for each region\n",
    "def select_pois_for_all_regions(boundary_gdf, motorway_gdf, trunk_gdf, poi_gdf, demand_map, target_crs):\n",
    "    all_selected_pois = []\n",
    "    for region_id in boundary_gdf['fid'].unique():\n",
    "        region_boundary = boundary_gdf[boundary_gdf['fid'] == region_id]\n",
    "        selected_pois_gdf = select_initial_pois_for_region(region_boundary, motorway_gdf, trunk_gdf, poi_gdf, demand_map, target_crs)\n",
    "        all_selected_pois.append(selected_pois_gdf)\n",
    "\n",
    "    # Combine all selected POIs into a single GeoDataFrame\n",
    "    if all_selected_pois:\n",
    "        return gpd.GeoDataFrame(pd.concat(all_selected_pois, ignore_index=True), crs=target_crs)\n",
    "    return None\n",
    "\n",
    "# Save selected POIs to file\n",
    "def save_selected_pois(selected_pois_gdf, output_file):\n",
    "    if selected_pois_gdf is not None:\n",
    "        selected_pois_gdf.to_file(output_file, driver=\"GPKG\")\n",
    "        print(f\"Total selected POIs: {len(selected_pois_gdf)}\")\n",
    "    else:\n",
    "        print(\"No POIs were selected.\")\n",
    "\n",
    "# Example of usage in a Jupyter notebook environment\n",
    "motorway_gdf, trunk_gdf, poi_gdf, demand_map, boundary_gdf = load_data()\n",
    "target_crs = 'EPSG:3857'  # Using EPSG:3857 which is meter-based and suitable for Euclidean distance\n",
    "\n",
    "# Select POIs for all regions\n",
    "selected_pois_gdf = select_pois_for_all_regions(boundary_gdf, motorway_gdf, trunk_gdf, poi_gdf, demand_map, target_crs)\n",
    "\n",
    "# Save the results\n",
    "save_selected_pois(selected_pois_gdf, 'atlanta_dcfc_initial.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-29 20:54:03,906 - INFO - \n",
      "==================================================\n",
      "*** Processed Polygon Information ***\n",
      "--------------------------------------------------\n",
      "Polygon ID            : Atlanta, GA Urban Area_6\n",
      "Total Supply          : 176.0\n",
      "A_bar Value           : 0.0014\n",
      "Selected Initial Sites: 5\n",
      "Initial Coverage      : 15.42%\n",
      "==================================================\n",
      "2024-09-29 20:54:09,869 - INFO - Selecting site  6/35 | Selected Site: 132 | A_hat: 0.00400 | Coverage:  15.42%\n",
      "2024-09-29 20:54:14,816 - INFO - Selecting site  7/35 | Selected Site: 107 | A_hat: 0.00369 | Coverage:  16.47%\n",
      "2024-09-29 20:54:18,011 - INFO - Selecting site  8/35 | Selected Site:   5 | A_hat: 0.00344 | Coverage:  19.11%\n",
      "2024-09-29 20:54:21,789 - INFO - Selecting site  9/35 | Selected Site: 102 | A_hat: 0.00323 | Coverage:  22.32%\n",
      "2024-09-29 20:54:26,077 - INFO - Selecting site 10/35 | Selected Site: 139 | A_hat: 0.00307 | Coverage:  25.20%\n",
      "2024-09-29 20:54:30,941 - INFO - Selecting site 11/35 | Selected Site: 208 | A_hat: 0.00293 | Coverage:  27.44%\n",
      "2024-09-29 20:54:34,134 - INFO - Selecting site 12/35 | Selected Site: 171 | A_hat: 0.00281 | Coverage:  29.46%\n",
      "2024-09-29 20:54:37,867 - INFO - Selecting site 13/35 | Selected Site:  80 | A_hat: 0.00270 | Coverage:  31.18%\n",
      "2024-09-29 20:54:42,105 - INFO - Selecting site 14/35 | Selected Site: 187 | A_hat: 0.00260 | Coverage:  32.98%\n",
      "2024-09-29 20:54:46,875 - INFO - Selecting site 15/35 | Selected Site: 158 | A_hat: 0.00251 | Coverage:  34.76%\n",
      "2024-09-29 20:54:50,066 - INFO - Selecting site 16/35 | Selected Site:  76 | A_hat: 0.00243 | Coverage:  36.69%\n",
      "2024-09-29 20:54:53,732 - INFO - Selecting site 17/35 | Selected Site:  64 | A_hat: 0.00236 | Coverage:  38.71%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m poi_gdf \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(poi_file)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, polygon \u001b[38;5;129;01min\u001b[39;00m polygons\u001b[38;5;241m.\u001b[39miterrows(): \n\u001b[0;32m---> 13\u001b[0m     \u001b[43mgreedy_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolygon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtif_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoi_gdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbandwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_intermediate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ACM-SIGSPATIAL-Cup-2024/src/greedy_optimization.py:116\u001b[0m, in \u001b[0;36mgreedy_optimization\u001b[0;34m(polygon, tif_file, poi_gdf, capture_range, bandwidth, constraints, output_path, save_intermediate)\u001b[0m\n\u001b[1;32m    113\u001b[0m best_Ai_optimized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Parallel optimization for candidate site selection\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msite\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_capacity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselected_sites\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43msite\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemand_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msite\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43msite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mremaining_candidate_sites\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m all_infinite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ((optimized_supply, Ai_optimized, A_hat), site) \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "File \u001b[0;32m/opt/anaconda/envs/sig2024/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda/envs/sig2024/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda/envs/sig2024/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "setup_logging()\n",
    "\n",
    "gpkg_file = \"/home/sehoon/Desktop/ACM-SIGSPATIAL-Cup-2024/data/for_model/urban_trip_DCFC_greedy.gpkg\"\n",
    "tif_file = \"/home/sehoon/Desktop/ACM-SIGSPATIAL-Cup-2024/data/demand_map_500.tif\"\n",
    "poi_file = \"/home/sehoon/Desktop/ACM-SIGSPATIAL-Cup-2024/data/for_model/Atlanta_Final_DCFAST_Candidate.gpkg\"\n",
    "output_path = \"./results/\"\n",
    "\n",
    "# Read input files\n",
    "polygons = gpd.read_file(gpkg_file)\n",
    "poi_gdf = gpd.read_file(poi_file)\n",
    "\n",
    "for _, polygon in polygons.iterrows(): \n",
    "    greedy_optimization(\n",
    "        polygon, \n",
    "        tif_file, \n",
    "        poi_gdf, \n",
    "        capture_range=3000, \n",
    "        bandwidth=1000, \n",
    "        constraints=(1, None), \n",
    "        output_path=output_path,\n",
    "        save_intermediate=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jiwan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
